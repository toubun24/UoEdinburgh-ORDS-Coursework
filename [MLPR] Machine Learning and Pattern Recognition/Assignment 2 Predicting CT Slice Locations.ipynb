{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751fb023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ct_support_code import *\n",
    "data = np.load('ct_data.npz')\n",
    "X_train = data['X_train']; X_val = data['X_val']; X_test = data['X_test']\n",
    "y_train = data['y_train']; y_val = data['y_val']; y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24aefbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 384)\n",
      "(40754,)\n",
      "(5785, 384)\n",
      "(5785,)\n",
      "(6961, 384)\n",
      "(6961,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(X_val))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539ea123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of y_train is: -9.13868774539957e-15\n",
      "corresponding standard error is: 0.0049535309340638205\n",
      "mean of y_val is: -0.2160085093241599\n",
      "corresponding standard error is: 0.01290449880016868\n",
      "mean of first 5785 y_train is: -0.44247687859693674\n",
      "corresponding standard error is: 0.011927303389170828\n"
     ]
    }
   ],
   "source": [
    "# a\n",
    "mean_y_train = np.mean(y_train)\n",
    "print('mean of y_train is:',mean_y_train)\n",
    "se_y_train = np.std(y_train,ddof=1)/np.sqrt(np.shape(y_train)[0])\n",
    "print('corresponding standard error is:',se_y_train)\n",
    "mean_y_val = np.mean(y_val)\n",
    "print('mean of y_val is:',mean_y_val)\n",
    "se_y_val = np.std(y_val,ddof=1)/np.sqrt(np.shape(y_val)[0])\n",
    "print('corresponding standard error is:',se_y_val)\n",
    "mean_y_train_5785 = np.mean(y_train[0:np.shape(y_val)[0]])\n",
    "print('mean of first 5785 y_train is:',mean_y_train_5785)\n",
    "se_y_train_5785 = np.std(y_train[0:np.shape(y_val)[0]],ddof=1)/np.sqrt(np.shape(y_val)[0])\n",
    "print('corresponding standard error is:',se_y_train_5785)\n",
    "\n",
    "# mean of y_train is: -9.13868774539957e-15\n",
    "# corresponding standard error is: 0.0049535309340638205\n",
    "# mean of y_val is: -0.2160085093241599\n",
    "# corresponding standard error is: 0.01290449880016868\n",
    "# mean of first 5785 y_train is: -0.44247687859693674\n",
    "# corresponding standard error is: 0.011927303389170828\n",
    "\n",
    "# for y_train, since sample size is large, its standard error is small, so that the sample mean is closer to population mean 0\n",
    "# while for y_val and first 5785 y_train, with smaller sample size, there standard errors are rather higher, leading some bias on sample mean from populaiton mean 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ac2b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.12519785]\n",
      "1 5785\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:1])\n",
    "print('1',np.shape(y_val)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dffe6d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.25 -0.25 -0.25 -0.25]]\n",
      "True\n",
      "False\n",
      "False\n",
      "40754\n",
      "384\n",
      "[[1 2 3]\n",
      " [4 5 3]]\n",
      "[[1 2]\n",
      " [4 5]]\n",
      "[[2 3]\n",
      " [5 3]]\n",
      "[1, 2]\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "[0. 0.]\n",
      "[1, 1, 1]\n",
      "[3, 3]\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:10,0:10])\n",
    "print(np.all(X_train[0:10,0]==X_train[0:10,1]))\n",
    "print(np.all(X_train[0:10,5]==X_train[0:10,6]))\n",
    "tmp=np.array([True,False,True])\n",
    "print(np.all(tmp))\n",
    "print(np.shape(X_train)[0])\n",
    "print(np.shape(X_train)[1])\n",
    "tmp1=np.array([[1,2,3],[4,5,3]])\n",
    "print(tmp1)\n",
    "tmp2=np.delete(tmp1,2,axis=1)\n",
    "print(tmp2)\n",
    "tmp3=np.delete(tmp1,0,axis=1)\n",
    "print(tmp3)\n",
    "tmp4=[]\n",
    "i=1\n",
    "j=2\n",
    "tmp4.append(i)\n",
    "tmp4.append(j)\n",
    "print(tmp4)\n",
    "tmp5=np.array([False,False,False])\n",
    "print(np.all(tmp5))\n",
    "tmp6=np.array([1,2,3])\n",
    "print(np.all(tmp6==tmp6[1]))\n",
    "tmp7=np.array([1,1,1])\n",
    "print(np.all(tmp7==tmp7[1]))\n",
    "print(np.all(tmp1[:,0]==[1,4]))\n",
    "print(np.zeros(2))\n",
    "print([1]*3)\n",
    "print([tmp1[0,2]]*2)\n",
    "print(np.all(tmp1[:,2]==[tmp1[0,2]]*2))\n",
    "print(np.all(tmp1[:,1]==2))\n",
    "print([1] in tmp6)\n",
    "print([4] in tmp6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14317f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted constant columns are: [59, 69, 179, 189, 351]\n",
      "deleted duplicate columns after constant columns delected are: [76, 77, 195, 185, 283, 354]\n"
     ]
    }
   ],
   "source": [
    "# b\n",
    "# delete constant columns\n",
    "deleted_constant_column = []\n",
    "for i in range(0,np.shape(X_train)[1]):\n",
    "    if(np.all(X_train[:,i]==X_train[0,i])):\n",
    "        deleted_constant_column.append(i)\n",
    "X_train=np.delete(X_train,deleted_constant_column,axis=1)\n",
    "print('deleted constant columns are:',deleted_constant_column)\n",
    "\n",
    "# delete duplicate columns\n",
    "deleted_duplicate_column = []\n",
    "for i in range(0,np.shape(X_train)[1]-1):\n",
    "    for j in range(i+1,np.shape(X_train)[1]):\n",
    "        if((j in deleted_duplicate_column)==False and np.all(X_train[:,i]==X_train[:,j])):\n",
    "            deleted_duplicate_column.append(j)\n",
    "X_train=np.delete(X_train,deleted_duplicate_column,axis=1)\n",
    "print('deleted duplicate columns after constant columns delected are:',deleted_duplicate_column)\n",
    "\n",
    "# delete constant columns in validation set and test set\n",
    "X_val=np.delete(X_val,deleted_constant_column,axis=1)\n",
    "X_test=np.delete(X_test,deleted_constant_column,axis=1)\n",
    "\n",
    "# delete duplicate columns in validation set and test set\n",
    "X_val=np.delete(X_val,deleted_duplicate_column,axis=1)\n",
    "X_test=np.delete(X_test,deleted_duplicate_column,axis=1)\n",
    "\n",
    "# deleted constant columns are: [59, 69, 179, 189, 351]\n",
    "# deleted duplicate columns after constant columns delected are: [76, 77, 195, 185, 283, 354]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0a9f32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5785, 373)\n",
      "(6961, 373)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_val))\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510e6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xx_preprocessing(X):\n",
    "    X_bias = np.concatenate([X, np.ones((X.shape[0],1))], axis=1)\n",
    "    rg = np.concatenate([np.eye(X.shape[1])*alpha, np.zeros((X.shape[1],1))], axis=1)\n",
    "    x = np.concatenate([X_bias, rg], axis=0)\n",
    "    return x\n",
    "def yy_preprocessing(X,yy):\n",
    "    y = np.concatenate([yy, np.zeros((X.shape[1],1))], axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a48613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 373)\n",
      "(40754, 374)\n",
      "[[2. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 2.]]\n",
      "373\n",
      "(4, 1)\n",
      "[[ 1.  2.  3.  1.]\n",
      " [ 4.  5.  6.  1.]\n",
      " [ 7.  8.  9.  1.]\n",
      " [10. 11. 12.  1.]\n",
      " [30.  0.  0.  0.]\n",
      " [ 0. 30.  0.  0.]\n",
      " [ 0.  0. 30.  0.]]\n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "X_bias = np.concatenate([X_train, np.ones((X_train.shape[0],1))], axis=1)\n",
    "print(np.shape(X_bias))\n",
    "print(np.eye(3)*2)\n",
    "#alpha=30\n",
    "print(X_train.shape[1])\n",
    "rg = np.eye(X_train.shape[1])*alpha\n",
    "tmp_x=np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "tmp_y=np.array([[1],[2],[3],[4]])\n",
    "print(np.shape(tmp_y))\n",
    "print(xx_preprocessing(tmp_x))\n",
    "print(yy_preprocessing(tmp_x,tmp_y))\n",
    "#fit_linreg(X=xx_preprocessing(tmp_x), yy=yy_preprocessing(tmp_x,tmp_y), alpha=30)\n",
    "#w_fit = np.linalg.lstsq(X, yy, rcond=None)[0]\n",
    "#y_train_lr = \n",
    "#w_fit = w_fit.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e71c632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set by fit_linreg is: 0.3567565397204055\n",
      "RMSE on training set by fit_linreg_gradopt is: 0.3567552912135179\n",
      "RMSE on validation set by fit_linreg is: 0.4230521968394694\n",
      "RMSE on validation set by fit_linreg_gradopt is: 0.4230626605868067\n"
     ]
    }
   ],
   "source": [
    "# c\n",
    "def fit_linreg(X, yy, alpha):\n",
    "    X_bias = np.concatenate([X, np.ones((X.shape[0],1))], axis=1)\n",
    "    rg = np.concatenate([np.eye(X.shape[1])*np.sqrt(alpha), np.zeros((X.shape[1],1))], axis=1)\n",
    "    x = np.concatenate([X_bias, rg], axis=0)\n",
    "    y = np.concatenate([np.array([yy]).T, np.zeros((X.shape[1],1))], axis=0)\n",
    "    w_fit = np.linalg.lstsq(x, y, rcond=None)[0]\n",
    "    return w_fit\n",
    "\n",
    "w_fit_lr = fit_linreg(X=X_train, yy=y_train, alpha=30)\n",
    "\n",
    "w_fit_gd1,w_fit_gd2 = fit_linreg_gradopt(X=X_train, yy=y_train, alpha=30)\n",
    "\n",
    "# preprocessing the estimate output from fit_linreg_gradopt\n",
    "def w_combine(w_x, w_c):\n",
    "    w = np.zeros((w_x.shape[0]+1,1))\n",
    "    w[0:w_x.shape[0]] = np.array([w_x]).T\n",
    "    w[w_x.shape[0]] = np.array([[w_c]])\n",
    "    return w\n",
    "\n",
    "w_fit_gd = w_combine(w_x=w_fit_gd1,w_c=w_fit_gd2)\n",
    "\n",
    "def predict(X, w):\n",
    "    X_bias = np.concatenate([X, np.ones((X.shape[0],1))], axis=1)\n",
    "    y_hat = np.dot(X_bias,w)\n",
    "    return y_hat\n",
    "\n",
    "def rmse_compute(X, yy, w):\n",
    "    n = yy.shape[0]\n",
    "    y_hat = predict(X, w)\n",
    "    rmse = np.sqrt(np.sum((np.array([yy]).T-y_hat)**2)/n)\n",
    "    return rmse\n",
    "\n",
    "# compare RMSE\n",
    "rmse_lr_train = rmse_compute(X=X_train, yy=y_train, w=w_fit_lr)\n",
    "print('RMSE on training set by fit_linreg is:',rmse_lr_train)\n",
    "rmse_gd_train = rmse_compute(X=X_train, yy=y_train, w=w_fit_gd)\n",
    "print('RMSE on training set by fit_linreg_gradopt is:',rmse_gd_train)\n",
    "rmse_lr_val = rmse_compute(X=X_val, yy=y_val, w=w_fit_lr)\n",
    "print('RMSE on validation set by fit_linreg is:',rmse_lr_val)\n",
    "rmse_gd_val = rmse_compute(X=X_val, yy=y_val, w=w_fit_gd)\n",
    "print('RMSE on validation set by fit_linreg_gradopt is:',rmse_gd_val)\n",
    "\n",
    "# RMSE on training set by fit_linreg is: 0.3567565397204055\n",
    "# RMSE on training set by fit_linreg_gradopt is: 0.3567552912135179\n",
    "# RMSE on validation set by fit_linreg is: 0.4230521968394694\n",
    "# RMSE on validation set by fit_linreg_gradopt is: 0.4230626605868067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5623d08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(374, 1)\n",
      "(374, 1)\n",
      "(40754, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(w_fit_lr))\n",
    "print(np.shape(w_fit_gd))\n",
    "print(np.shape(np.array([y_train]).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "90276370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9], dtype=int32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,2,3])\n",
    "b=np.array([4,5,6])\n",
    "(a-b)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "211b6840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on logistic probability training set by fit_linreg is: 0.1544115042988901\n",
      "RMSE on logistic probability training set by fit_linreg is: 0.2542477297775173\n"
     ]
    }
   ],
   "source": [
    "# d\n",
    "def fit_logreg_gradopt(X, yy, alpha):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb\n",
    "\n",
    "def sigmoid(X):\n",
    "    sg = np.divide(1,(1+np.exp(-X)))\n",
    "    return sg\n",
    "\n",
    "K = 20 # number of thresholded classification problems to fit\n",
    "N = X_train.shape[1]\n",
    "X_train_prob = np.zeros(shape=(X_train.shape[0],K))\n",
    "X_val_prob = np.zeros(shape=(X_val.shape[0],K))\n",
    "mx = np.max(y_train); mn = np.min(y_train); hh = (mx-mn)/(K+1)\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "\n",
    "# record the initial parameters that will be used in the next problem\n",
    "ww_q3_init = np.zeros(shape=(K))\n",
    "bb_q3_init = 0\n",
    "V_q3_init = np.zeros(shape=(K,N))\n",
    "bk_q3_init = np.zeros(shape=(K))\n",
    "\n",
    "# iteration for K=20\n",
    "for kk in range(K):\n",
    "    labels = y_train > thresholds[kk]\n",
    "    # ... fit logistic regression to these labels\n",
    "    w_fit_log_gd1,w_fit_log_gd2 = fit_logreg_gradopt(X=X_train, yy=labels, alpha=30)\n",
    "    w_fit_log_gd = w_combine(w_x=w_fit_log_gd1,w_c=w_fit_log_gd2)\n",
    "    X_train_prob[:,kk] = sigmoid(predict(X_train, w_fit_log_gd).ravel())\n",
    "    X_val_prob[:,kk] = sigmoid(predict(X_val, w_fit_log_gd).ravel())\n",
    "    # record the initial parameters that will be used in the next problem\n",
    "    V_q3_init[kk,:] = w_fit_log_gd1\n",
    "    bk_q3_init[kk] = w_fit_log_gd2\n",
    "\n",
    "# fit\n",
    "w_log_lr = fit_linreg(X=X_train_prob, yy=y_train, alpha=30)\n",
    "# record the initial parameters that will be used in the next problem\n",
    "ww_q3_init = w_log_lr[0:-1].ravel()\n",
    "bb_q3_init = w_log_lr[-1]\n",
    "\n",
    "# predict and compute RMSE\n",
    "rmse_log_lr_train = rmse_compute(X=X_train_prob, yy=y_train, w=w_log_lr)\n",
    "print('RMSE on logistic probability training set by fit_linreg is:',rmse_log_lr_train)\n",
    "rmse_log_lr_val = rmse_compute(X=X_val_prob, yy=y_val, w=w_log_lr)\n",
    "print('RMSE on logistic probability training set by fit_linreg is:',rmse_log_lr_val)\n",
    "\n",
    "# RMSE on logistic probability training set by fit_linreg is: 0.1544115042988901\n",
    "# RMSE on logistic probability training set by fit_linreg is: 0.2542477297775173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc89ac0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(w_fit_log_gd)\n",
    "w_fit_log_gd1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa6e6f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 1)\n",
      "(40754,)\n",
      "(40754, 1)\n",
      "(20,)\n",
      "6\n",
      "[1 2 3 4 5]\n",
      "[1 2 3 4 5 6]\n",
      "373\n",
      "(40754, 20)\n",
      "(20,)\n",
      "(1,)\n",
      "(20, 373)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(np.array(predict(X_train, w_fit_log_gd))))\n",
    "print(np.shape(X_train_prob[:,kk]))\n",
    "print(np.shape(predict(X_train, w_fit_log_gd)))\n",
    "print(np.shape(np.zeros(shape=(K))))\n",
    "tmpneg1=np.array([1,2,3,4,5,6])\n",
    "print(tmpneg1[-1])\n",
    "print(tmpneg1[0:-1])\n",
    "print(tmpneg1[0:6])\n",
    "print(X_train.shape[1])\n",
    "print(np.shape(X_train_prob))\n",
    "print(np.shape(ww_q3_init))\n",
    "print(np.shape(bb_q3_init))\n",
    "print(np.shape(V_q3_init))\n",
    "print(np.shape(bk_q3_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a09a5b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set by neural network with random initialization is: 0.14495698828371573\n",
      "RMSE on training set by neural network with initialization from Q3 is: 0.13964661059373618\n",
      "RMSE on validation set by neural network with random initialization is: 0.27736179585093423\n",
      "RMSE on validation set by neural network with initialization from Q3 is: 0.2678848469412657\n"
     ]
    }
   ],
   "source": [
    "# e\n",
    "def fit_nn(X, yy, alpha, K, ww0=None, bb0=None, V0=None, bk0=None):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    # just for comparing reason in the following questions, we set the same random initialization using seed()\n",
    "    if ww0 is None:\n",
    "        np.random.seed(400)\n",
    "        ww_init = 0.1*np.random.randn(K)/np.sqrt(K)\n",
    "    else:\n",
    "        ww_init = ww0\n",
    "    if bb0 is None:\n",
    "        np.random.seed(300)\n",
    "        bb_init = 0.1*np.random.randn(1)/np.sqrt(K)\n",
    "    else:\n",
    "        bb_init = bb0\n",
    "    if V0 is None:\n",
    "        np.random.seed(200)\n",
    "        V_init = 0.1*np.random.randn(K,D)/np.sqrt(D)\n",
    "    else:\n",
    "        V_init = V0\n",
    "    if bk0 is None:\n",
    "        np.random.seed(100)\n",
    "        bk_init = 0.1*np.random.randn(K)/np.sqrt(D)\n",
    "    else:\n",
    "        bk_init = bk0\n",
    "    init = (ww_init, bb_init, V_init, bk_init)\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk\n",
    "\n",
    "# fit\n",
    "params_rd = fit_nn(X=X_train, yy=y_train, alpha=30, K=20)\n",
    "params_q3 = fit_nn(X=X_train, yy=y_train, alpha=30, K=20, ww0=ww_q3_init, bb0=bb_q3_init, V0=V_q3_init, bk0=bk_q3_init)\n",
    "\n",
    "# predict and compute RMSE under neural network framework\n",
    "def rmse_compute_nn(X, yy, params):\n",
    "    n = yy.shape[0]\n",
    "    y_hat = nn_cost(params, X)\n",
    "    rmse = np.sqrt(np.sum((yy-y_hat)**2)/n)\n",
    "    return rmse\n",
    "\n",
    "# output and compare RMSE\n",
    "rmse_nn_rd_train = rmse_compute_nn(X=X_train, yy=y_train, params=params_rd)\n",
    "print('RMSE on training set by neural network with random initialization is:',rmse_nn_rd_train)\n",
    "rmse_nn_q3_train = rmse_compute_nn(X=X_train, yy=y_train, params=params_q3)\n",
    "print('RMSE on training set by neural network with initialization from Q3 is:',rmse_nn_q3_train)\n",
    "rmse_nn_rd_val = rmse_compute_nn(X=X_val, yy=y_val, params=params_rd)\n",
    "print('RMSE on validation set by neural network with random initialization is:',rmse_nn_rd_val)\n",
    "rmse_nn_q3_val = rmse_compute_nn(X=X_val, yy=y_val, params=params_q3)\n",
    "print('RMSE on validation set by neural network with initialization from Q3 is:',rmse_nn_q3_val)\n",
    "\n",
    "# RMSE on training set by neural network with random initialization is: 0.14495698828371573\n",
    "# RMSE on training set by neural network with initialization from Q3 is: 0.13964661059373618\n",
    "# RMSE on validation set by neural network with random initialization is: 0.27736179585093423\n",
    "# RMSE on validation set by neural network with initialization from Q3 is: 0.2678848469412657\n",
    "# As for initialization strategy, the one with results from Q3 works slightly better than random initialization.\n",
    "# While compared with model in Q3, we find that the neural network performs better on training set but worse on initialization set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69301203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17497655,  0.03426804,  0.11530358, -0.0252436 ,  0.09813208,\n",
       "        0.05142188,  0.02211797, -0.10700433, -0.01894958,  0.02550014,\n",
       "       -0.0458027 ,  0.04351635, -0.05835951,  0.08168471,  0.06727208,\n",
       "       -0.01044111, -0.05312804,  0.10297327, -0.04381356, -0.11183182])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "ww_init = 0.1*np.random.randn(20)\n",
    "ww_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8479f463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set by neural network with random initialization is: 0.0007168954265953701\n",
      "RMSE on training set by neural network with initialization from Q3 is: 0.000688797717556736\n",
      "RMSE on validation set by neural network with random initialization is: 0.0035324094652553315\n",
      "RMSE on validation set by neural network with initialization from Q3 is: 0.003551373731332015\n"
     ]
    }
   ],
   "source": [
    "#w_fit_log_gd = w_combine(w_x=w_fit_log_gd1,w_c=w_fit_log_gd2)\n",
    "rmse_nn_rd_train_10 = 0\n",
    "rmse_nn_rd_val_10 = 0\n",
    "for i in range(10):\n",
    "    params_rd_10 = fit_nn(X=X_train, yy=y_train, alpha=30, K=20)\n",
    "    rmse_nn_rd_train_10 = rmse_nn_rd_train_10+rmse_compute_nn(X=X_train, yy=y_train, params=params_rd_10)\n",
    "    rmse_nn_rd_val_10 = rmse_nn_rd_val_10+rmse_compute_nn(X=X_val, yy=y_val, params=params_rd_10)\n",
    "rmse_nn_rd_train_10 = rmse_nn_rd_train_10/10\n",
    "rmse_nn_rd_val_10 = rmse_nn_rd_val_10/10\n",
    "print('RMSE on training set by neural network with random initialization for 10 trials average is:',rmse_nn_rd_train_10)\n",
    "print('RMSE on validation set by neural network with random initialization for 10 trials average is:',rmse_nn_rd_val_10)\n",
    "#nn_cost(params, X)\n",
    "#RMSE on logistic probability training set by fit_linreg is: 0.1604188075136425\n",
    "#RMSE on logistic probability training set by fit_linreg is: 0.25227247507537426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09177fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100, 1)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(nn_cost(params=params_rd, X=X_train[0:100,:])))\n",
    "print(np.shape(np.array([y_train[0:100]]).T))\n",
    "print(np.shape(y_train[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d36129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.23901655  0.20952115  0.16393735  0.15589317  0.19879556  0.21220256\n",
      "  0.34090973  0.29532593  0.30873292  0.24974213  0.18806998  0.17466294\n",
      "  0.34359114  0.15857458  0.21488397  0.32750273  0.31945851  0.25510495\n",
      "  0.23097237  0.33018414  0.29264452  0.25778636  0.25242354  0.13712336\n",
      "  0.31141433  0.30605152  0.18538857  0.33554691  0.23633514  0.23365373\n",
      "  0.21756533  0.19611416  0.17734435  0.35699813  0.34895391  0.37576794\n",
      "  0.24706072  0.38113071  0.32482133  0.30337015  0.24437936  0.22560955\n",
      "  0.18002575  0.35431672  0.30068875  0.28728175  0.26851194  0.17198158\n",
      "  0.26583053  0.31409574  0.22024674  0.20683974  0.22292814  0.37040512\n",
      "  0.35967954  0.33286555  0.28460034  0.16125594  0.43744009  0.3784493\n",
      "  0.26046776  0.27923753  0.27119335  0.20147697  0.37308653  0.27655612\n",
      "  0.36504231  0.26314913  0.29800734  0.27387476  0.36772372  0.31677715\n",
      "  0.3623609   0.20415833  0.3918563  -1.12045298 -1.11777158 -1.05878078\n",
      " -1.10704599 -1.10168317 -1.11240876 -1.11509017 -1.10436458 -1.09900177\n",
      " -1.08559477 -1.09095759 -1.06146219 -1.06682501 -1.07755059 -1.08827618\n",
      "  0.40258193  0.33822832  0.34627254  0.28996311  0.24169795 -1.09632036\n",
      "  0.38917493  0.35163531  0.28191894 -1.093639  ]\n",
      "[ 0.73092214  0.63935763  0.35466566  0.51315597  0.51006399  0.55395875\n",
      "  0.62683235  0.67312209  0.57538635  0.6092419   0.47159947  0.39154228\n",
      "  0.63414378  0.58784561  0.56864875  0.39506854  0.60866526  0.61993703\n",
      "  0.58674763  0.59957478  0.67590815  0.75456568  0.73161368  0.55089008\n",
      "  0.55756508  0.64478717  0.44416377  0.67919534  0.81553126  0.74546675\n",
      "  0.68314606  0.56794691  0.42326442  0.72157119  0.65062402  0.68459554\n",
      "  0.6416819   0.7727934   0.50902621  0.65248851  0.65821546  0.6553494\n",
      "  0.39970622  0.62083532  0.63684096  0.66779439  0.54904401  0.43624069\n",
      "  0.57877274  0.53693756  0.61921929  0.5554894   0.69207647  0.80100604\n",
      "  0.58217241  0.57794718  0.63166272  0.44389009  0.83504814  0.85773902\n",
      "  0.70215639  0.60493439  0.52566845  0.62175872  0.59673278  0.54069467\n",
      "  0.69262159  0.60415478  0.66638151  0.59141577  0.79709371  0.62761229\n",
      "  0.71989272  0.60384875  0.83432558 -0.88803255 -0.8456278  -0.79858222\n",
      " -0.69149923 -0.81753125 -0.7993222  -0.82045706 -0.78128038 -0.63823459\n",
      " -0.63644609 -0.52195201 -0.79196177 -0.82541055 -0.50084112 -0.49016991\n",
      "  0.82424674  0.58231535  0.66569537  0.65082921  0.77341562 -0.808942\n",
      "  0.83243049  0.72427745  0.57442911 -0.67699023]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(ww_rd)\n",
    "#print(bb_rd)\n",
    "#print(V_rd)\n",
    "#print(bk_rd)\n",
    "print(y_val[0:100])\n",
    "print(nn_cost(params=params_rd, X=X_val[0:100,:]))\n",
    "plt.clf()\n",
    "plt.plot(y_val[0:100],nn_cost(params=params_rd, X=X_val[0:100,:]),\".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c3f1115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def probimprov(rmse_3, baseline, alpha_n, alpha_range):\n",
    "    yn = np.log(baseline)-np.log(rmse_3)\n",
    "    ymax = np.max(yn)\n",
    "    X_rest = list(alpha_range)\n",
    "    for i in range(alpha_n.shape(0)):\n",
    "        X_rest.remove(alpha_3[i])\n",
    "    X_rest = np.array(X_rest)\n",
    "    post_mean, post_cov = gp_post_par(X_rest=X_rest, X_obs=alpha_3, yy=yn)\n",
    "    post_std = np.sqrt(np.diag(post_cov))\n",
    "    pi = stats.norm.cdf(np.divide((post_mean-ymax),post_std))\n",
    "    return pi, X_rest\n",
    "\n",
    "pi, X_rest = probimprov(rmse_3=rmse_3, baseline=rmse_nn_rd_val, alpha_3=alpha_3, alpha_range=np.arange(0, 50, 0.02))\n",
    "#post_mean, post_cov = probimprov(rmse_3=rmse_3, baseline=rmse_nn_rd_val, alpha_3=alpha_3, alpha_range=np.arange(0, 50, 0.02))\n",
    "#print(post_mean)\n",
    "#print(np.shape(pi))\n",
    "#print(pi)\n",
    "#print(max(pi))\n",
    "x=np.argmax(pi)\n",
    "print(x)\n",
    "\n",
    "#print(rmse_3-rmse_nn_rd_val)\n",
    "\n",
    "#gp_post_par(X_rest, X_obs, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7518176d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.array(alpha_n).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b666e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "y=0\n",
    "print(y)\n",
    "y=np.array([y])\n",
    "print(y)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31d8175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2734248988845852, 0.2715194856339719, 0.27528342783056226]\n",
      "[37.44, 31.580000000000002, 32.08]\n",
      "3\n",
      "(3,)\n",
      "(2497,)\n",
      "[0.05405095 0.05405095 0.05405095 ... 0.05567352 0.05565787 0.05564233]\n"
     ]
    }
   ],
   "source": [
    "#pi = probimprov(rmse_n=rmse_3, baseline=rmse_nn_rd_val, alpha_n=alpha_3, a_n=3, X_rest=np.arange(0, 50, 0.02))\n",
    "#print(pi)\n",
    "#x=np.arange(0, 50, 0.02)\n",
    "#print(np.shape(np.array(x)))\n",
    "#print(np.shape(np.array(alpha_3)))\n",
    "#x1=list(x)\n",
    "#x2=list(alpha_3)\n",
    "#print(np.shape(np.array(x1)))\n",
    "#print(np.shape(np.array(x2)))\n",
    "print(rmse_n)\n",
    "print(alpha_n)\n",
    "print(a_n)\n",
    "print(np.shape(alpha_n))\n",
    "print(np.shape(X_rest))\n",
    "pi = probimprov(rmse_n=rmse_n, baseline=rmse_nn_rd_val, alpha_n=np.array(alpha_n).ravel(), a_n=a_n, X_rest=X_rest)\n",
    "print(pi)\n",
    "#return rmse_n,alpha_n,a_n,X_rest\n",
    "#rmse_n,alpha_n,a_n,X_rest = bayesian_alpha_opt(alpha_range=alpha_range, a_n=a_n, iteration=iteration)\n",
    "#alpha_n.append(list(alpha_pick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "57d98c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.14]\n",
      "[44.7]\n",
      "[48.68]\n",
      "[10.52]\n",
      "[49.16]\n",
      "10.84\n",
      "9.1\n",
      "12.08\n",
      "12.26\n",
      "12.24\n",
      "12.280000000000001\n",
      "12.22\n",
      "After Bayesian optimisation, the optimal alpha is: 12.08 , with corresponding optimal RMSE_val_a: 0.2516389695243346\n",
      "RMSE_test_a is: 0.2824027477387918\n"
     ]
    }
   ],
   "source": [
    "# f\n",
    "from scipy import stats\n",
    "\n",
    "# return neural network RMSE_val by a given alpha\n",
    "def train_nn_reg(alpha):\n",
    "    params = fit_nn(X=X_train, yy=y_train, alpha=alpha, K=20)\n",
    "    rmse_nn_rd_val = rmse_compute_nn(X=X_val, yy=y_val, params=params)\n",
    "    return rmse_nn_rd_val\n",
    "\n",
    "# acquisition function\n",
    "def probimprov(rmse_n, baseline, alpha_n, X_rest):\n",
    "    yn = np.log(baseline)-np.log(rmse_n)\n",
    "    ymax = np.max(yn)\n",
    "    post_mean, post_cov = gp_post_par(X_rest=np.array(X_rest), X_obs=np.array(alpha_n), yy=yn)\n",
    "    post_std = np.sqrt(np.diag(post_cov))\n",
    "    pi = stats.norm.cdf(np.divide((post_mean-ymax),post_std))\n",
    "    return pi\n",
    "\n",
    "# optimize alpha in iteration\n",
    "def bayesian_alpha_opt(alpha_range, a_n, iteration):\n",
    "    alpha_n = []\n",
    "    rmse_n = []\n",
    "    X_rest = list(alpha_range)\n",
    "    for i in range(a_n):\n",
    "        np.random.seed()\n",
    "        alpha_pick = np.random.choice(list(alpha_range), 1, replace=False)\n",
    "        print(alpha_pick)\n",
    "        alpha_n.append(alpha_pick[0])\n",
    "        X_rest.remove(alpha_pick[0])\n",
    "        rmse_n.append(train_nn_reg(alpha=alpha_pick))\n",
    "    for i in range(iteration):\n",
    "        pi = probimprov(rmse_n=rmse_n, baseline=rmse_nn_rd_val, alpha_n=np.array(alpha_n).ravel(), X_rest=X_rest)\n",
    "        index_nplus1 = np.argmax(pi)\n",
    "        alpha_nplus1 = X_rest[index_nplus1]\n",
    "        print(alpha_nplus1)\n",
    "        alpha_n.append(alpha_nplus1)\n",
    "        a_n = a_n+1\n",
    "        X_rest.remove(alpha_nplus1)\n",
    "        rmse_n.append(train_nn_reg(alpha=alpha_nplus1))\n",
    "    index_opt = np.argmin(rmse_n)\n",
    "    alpha_opt = alpha_n[index_opt]\n",
    "    rmse_opt = rmse_n[index_opt]\n",
    "    return alpha_opt, rmse_opt\n",
    "\n",
    "a_n = 5\n",
    "iteration = 7\n",
    "alpha_range = np.arange(0, 50, 0.02)\n",
    "alpha_opt, rmse_opt = bayesian_alpha_opt(alpha_range=alpha_range, a_n=a_n, iteration=iteration)\n",
    "print('After Bayesian optimisation, the optimal alpha is:', alpha_opt, ', with corresponding optimal RMSE_val_a:',rmse_opt)\n",
    "params = fit_nn(X=X_train, yy=y_train, alpha=alpha_opt, K=20)\n",
    "rmse_test_a = rmse_compute_nn(X=X_test, yy=y_test, params=params)\n",
    "print('RMSE_test_a is:',rmse_test_a)\n",
    "#After Bayesian optimisation, the optimal alpha is: 4.16 , with corresponding optimal RMSE_val_a: 0.24575694603974121\n",
    "#RMSE_test_a is: 0.2712213928951255\n",
    "#After Bayesian optimisation, the optimal alpha is: 2.9 , with corresponding optimal RMSE_val_a: 0.24249353747635613\n",
    "#RMSE_test_a is: 0.2640520595005275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "710371c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 9]\n",
      "4\n",
      "5\n",
      "[0.000e+00 2.000e-02 4.000e-02 ... 4.994e+01 4.996e+01 4.998e+01]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'alpha_pick' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9558aa219e93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# After Bayesian optimisation, the optimal alpha is: 14.8 , with corresponding optimal RMSE_val_a: 0.2542724999123373\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_pick\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'alpha_pick' is not defined"
     ]
    }
   ],
   "source": [
    "tmp3 = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(np.diag(tmp3))\n",
    "tmp4=np.array([1,2,3,4,5])\n",
    "print(np.argmax(tmp4))\n",
    "print(tmp4[4])\n",
    "# After Bayesian optimisation, the optimal alpha is: 11.8 , with corresponding optimal RMSE_val_a: 0.2443455580795231\n",
    "# After Bayesian optimisation, the optimal alpha is: 14.8 , with corresponding optimal RMSE_val_a: 0.2542724999123373\n",
    "print(alpha_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = fit_nn(X=X_train, yy=y_train, alpha=alpha_opt, K=20)\n",
    "rmse_test_a = rmse_compute_nn(X=X_test, yy=y_test, params=params)\n",
    "print('RMSE_test_a is:',rmse_test_a)\n",
    "params = fit_nn(X=X_train, yy=y_train, alpha=alpha_opt, K=20)\n",
    "rmse_test_a = rmse_compute_nn(X=X_test, yy=y_test, params=params)\n",
    "print('RMSE_test_a is:',rmse_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "675865a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9407914639148472\n",
      "-0.9407914639148472\n",
      "1.012953967134065\n",
      "0.46458471522694583\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2222)\n",
    "print(np.random.randn())\n",
    "np.random.seed(2222)\n",
    "print(np.random.randn())\n",
    "\n",
    "print(np.random.randn())\n",
    "print(np.random.randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9e45d708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[8 9 6]\n",
      "None\n",
      "[0, 1, 2, 3, 4, 5, 7]\n",
      "[8 9 6]\n"
     ]
    }
   ],
   "source": [
    "alpha_range = list(np.arange(0, 10, 1))\n",
    "print(alpha_range)\n",
    "alpha_3 = np.random.choice(alpha_range, 3, replace=False)\n",
    "print(alpha_3)\n",
    "for i in range(3):\n",
    "    tmp2 = alpha_range.remove(alpha_3[i])\n",
    "print(tmp2)\n",
    "print(alpha_range)\n",
    "print(alpha_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7567566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2561773  0.26302672 0.26645656]\n"
     ]
    }
   ],
   "source": [
    "# return neural network RMSE_val by a given alpha\n",
    "def train_nn_reg(alpha):\n",
    "    params = fit_nn(X=X_train, yy=y_train, alpha=alpha, K=20)\n",
    "    rmse_nn_rd_val = rmse_compute_nn(X=X_val, yy=y_val, params=params)\n",
    "    return rmse_nn_rd_val\n",
    "\n",
    "alpha_range = list(np.arange(0, 50, 0.02))\n",
    "alpha_3 = np.random.choice(alpha_range, 3, replace=False)\n",
    "\n",
    "rmse_3 = np.zeros(shape=(3))\n",
    "for i in range(3):\n",
    "    rmse_3[i] = train_nn_reg(alpha_3[i])\n",
    "    \n",
    "print(rmse_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9523183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "[-0.88805632 -1.06472892  0.74447972 -0.69620414  0.07720457 -0.72209727\n",
      "  0.9101895  -0.18604106  1.31101366 -0.48143618]\n",
      "(3,)\n",
      "[12.64 49.36 39.98]\n"
     ]
    }
   ],
   "source": [
    "X_grid = np.arange(0, 10, 1)[:,None]\n",
    "N_grid = X_grid.shape[0]\n",
    "#f_grid = np.dot(L_grid, np.random.randn(N_grid))\n",
    "print(X_grid)\n",
    "print(np.random.randn(N_grid))\n",
    "tmps=list(np.array([1,2,3,4,5,6,7,8,9]))\n",
    "#np.random.sample(seq=tmps, size=3)\n",
    "aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
    "np.random.choice(aa_milne_arr, 5)\n",
    "np.random.choice(tmps, 5, replace=False)\n",
    "rmse_3 = np.zeros(shape=(3))\n",
    "print(np.shape(rmse_3))\n",
    "print(alpha_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9b455f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27574439466468037\n"
     ]
    }
   ],
   "source": [
    "alpha = 10000\n",
    "print(train_nn_reg(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "838f48fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation set by fit_linreg_gradopt is: 0.4305067287239561\n"
     ]
    }
   ],
   "source": [
    "w_fit_gd1,w_fit_gd2 = fit_linreg_gradopt(X=X_train, yy=y_train, alpha=1000)\n",
    "w_fit_gd = w_combine(w_x=w_fit_gd1,w_c=w_fit_gd2)\n",
    "rmse_gd_val = rmse_compute(X=X_val, yy=y_val, w=w_fit_gd)\n",
    "print('RMSE on validation set by fit_linreg_gradopt is:',rmse_gd_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4929acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9203384610945223\n"
     ]
    }
   ],
   "source": [
    "def nn_cost(params, X, yy=None, alpha=None):\n",
    "    # Unpack parameters from list\n",
    "    ww, bb, V, bk = params\n",
    "\n",
    "    # Forwards computation of cost\n",
    "    A = np.dot(X, V.T) + bk[None,:] # N,K\n",
    "    P = 1 / (1 + np.exp(-A)) # N,K\n",
    "    F = np.dot(P, ww) + bb # N,\n",
    "    if yy is None:\n",
    "        # user wants prediction rather than training signal:\n",
    "        return F\n",
    "    res = F - yy # N,\n",
    "    E = np.dot(res, res) + alpha*(np.sum(V*V) + np.dot(ww,ww)) # 1x1\n",
    "\n",
    "    # Reverse computation of gradients\n",
    "    F_bar = 2*res # N,\n",
    "    ww_bar = np.dot(P.T, F_bar) + 2*alpha*ww # K,\n",
    "    bb_bar = np.sum(F_bar) # scalar\n",
    "    P_bar = np.dot(F_bar[:,None], ww[None,:]) # N,\n",
    "    A_bar = P_bar * P * (1 - P) # N,\n",
    "    V_bar = np.dot(A_bar.T, X) + 2*alpha*V # K,\n",
    "    bk_bar = np.sum(A_bar, 0)\n",
    "\n",
    "    return E, (ww_bar, bb_bar, V_bar, bk_bar)\n",
    "\n",
    "def minimize_list(cost, init_list, args):\n",
    "    opt = {'maxiter': 500, 'disp': False}\n",
    "    init, unwrap = params_wrap(init_list)\n",
    "    def wrap_cost(vec, *args):\n",
    "        E, params_bar = cost(unwrap(vec), *args)\n",
    "        vec_bar, _ = params_wrap(params_bar)\n",
    "        return E, vec_bar\n",
    "    res = minimize(wrap_cost, init, args, 'L-BFGS-B', jac=True, options=opt)\n",
    "    return unwrap(res.x)\n",
    "\n",
    "def fit_nn(X, yy, alpha, K, ww0=None, bb0=None, V0=None, bk0=None):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    if ww0 is None:\n",
    "        ww_init = 0.1*np.random.randn(K)/np.sqrt(K)\n",
    "    else:\n",
    "        ww_init = ww0\n",
    "    if bb0 is None:\n",
    "        bb_init = 0.1*np.random.randn(1)\n",
    "    else:\n",
    "        bb_init = bb0\n",
    "    if V0 is None:\n",
    "        V_init = 0.1*np.random.randn(K,D)/np.sqrt(K*D)\n",
    "    else:\n",
    "        V_init = V0\n",
    "    if bk0 is None:\n",
    "        bk_init = 0.1*np.random.randn(K)/np.sqrt(K)\n",
    "    else:\n",
    "        bk_init = bk0\n",
    "    init = (ww_init, bb_init, V_init, bk_init)\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk\n",
    "def rmse_compute_nn(X, yy, params):\n",
    "    n = yy.shape[0]\n",
    "    y_hat = nn_cost(params, X)\n",
    "    rmse = np.sqrt(np.sum((yy-y_hat)**2)/n)\n",
    "    return rmse\n",
    "def train_nn_reg(alpha):\n",
    "    params = fit_nn(X=X_train, yy=y_train, alpha=alpha, K=20)\n",
    "    rmse_nn_rd_val = rmse_compute_nn(X=X_val, yy=y_val, params=params)\n",
    "    return rmse_nn_rd_val\n",
    "alpha = 10000\n",
    "print(train_nn_reg(alpha=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cc0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args\n",
    "def wrap_cost(vec, *args):\n",
    "        E, params_bar = cost(unwrap(vec), *args)\n",
    "        vec_bar, _ = params_wrap(params_bar)\n",
    "        return E, vec_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7dc0fcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.72]\n",
      "[27.64]\n",
      "[45.5]\n",
      "[30.26]\n",
      "[10.46]\n",
      "[13.1]\n",
      "[20.6]\n",
      "[34.16]\n",
      "[11.42]\n",
      "[36.76]\n",
      "9.44\n",
      "8.96\n",
      "8.98\n",
      "9.0\n",
      "8.94\n",
      "With increased initial alpha number: 10 , and increased iteration number:  5 , after Bayesian optimisation, the optimal alpha is:  9.44 , with corresponding optimal RMSE_val_aa:  0.2502031441711337\n",
      "RMSE_test_aa is: 0.28523318568832995\n"
     ]
    }
   ],
   "source": [
    "# g1\n",
    "a_n = 5\n",
    "iteration = 10\n",
    "alpha_range = np.arange(0, 50, 0.02)\n",
    "alpha_opt, rmse_opt = bayesian_alpha_opt(alpha_range=alpha_range, a_n=a_n, iteration=iteration)\n",
    "print('With increased initial alpha number:',a_n,', and increased iteration number: ',iteration,', after Bayesian optimisation, the optimal alpha is: ', alpha_opt, ', with corresponding optimal RMSE_val_aa: ',rmse_opt)\n",
    "params = fit_nn(X=X_train, yy=y_train, alpha=alpha_opt, K=20)\n",
    "rmse_test_aa = rmse_compute_nn(X=X_test, yy=y_test, params=params)\n",
    "print('RMSE_test_aa is:',rmse_test_aa)\n",
    "\n",
    "# With increased initial alpha number:  5 and increased iteration number: 10 , after Bayesian optimisation, the optimal alpha is:  5.0200000000000005 , with corresponding optimal RMSE_val_aa:  0.2323119954372763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8908d091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Bayesian optimisation, under alpha_opt = 2.9 the optimal k is: 22 , with corresponding optimal RMSE_val_az: 0.2342811823511767\n",
      "RMSE_test_az is: 0.2733534574343315\n"
     ]
    }
   ],
   "source": [
    "# g2\n",
    "alpha_opt=2.9\n",
    "# return neural network RMSE_val by a given K under optimal alpha from the previous step\n",
    "def train_nn_reg_k(K):\n",
    "    params = fit_nn(X=X_train, yy=y_train, alpha=alpha_opt, K=K)\n",
    "    rmse_nn_rd_val = rmse_compute_nn(X=X_val, yy=y_val, params=params)\n",
    "    return rmse_nn_rd_val\n",
    "\n",
    "# acquisition function\n",
    "def probimprov_k(rmse_n, baseline, k_n, X_rest):\n",
    "    yn = np.log(baseline)-np.log(rmse_n)\n",
    "    ymax = np.max(yn)\n",
    "    post_mean, post_cov = gp_post_par(X_rest=np.array(X_rest), X_obs=np.array(k_n), yy=yn)\n",
    "    post_std = np.sqrt(np.diag(post_cov))\n",
    "    pi = stats.norm.cdf(np.divide((post_mean-ymax),post_std))\n",
    "    return pi\n",
    "\n",
    "# optimize k in iteration\n",
    "def bayesian_k_opt(k_range, k0_n, iteration):\n",
    "    k_n = []\n",
    "    rmse_n = []\n",
    "    X_rest = list(k_range)\n",
    "    for i in range(k0_n):\n",
    "        np.random.seed()\n",
    "        k_pick = np.random.choice(list(k_range), 1, replace=False)\n",
    "        k_n.append(k_pick[0])\n",
    "        X_rest.remove(k_pick)\n",
    "        rmse_n.append(train_nn_reg_k(K=int(k_pick)))\n",
    "    for i in range(iteration):\n",
    "        pi = probimprov_k(rmse_n=rmse_n, baseline=rmse_nn_rd_val, k_n=np.array(k_n).ravel(), X_rest=X_rest)\n",
    "        index_nplus1 = np.argmax(pi)\n",
    "        k_nplus1 = X_rest[index_nplus1]\n",
    "        k_n.append(k_nplus1)\n",
    "        k0_n = k0_n+1\n",
    "        X_rest.remove(k_nplus1)\n",
    "        rmse_n.append(train_nn_reg_k(K=int(k_nplus1)))\n",
    "    index_opt = np.argmin(rmse_n)\n",
    "    k_opt = k_n[index_opt]\n",
    "    rmse_opt = rmse_n[index_opt]\n",
    "    return k_opt, rmse_opt\n",
    "\n",
    "k0_n = 3\n",
    "iteration = 5\n",
    "k_range = np.arange(0, 40, 1)\n",
    "k_opt, rmse_opt = bayesian_k_opt(k_range=k_range, k0_n=k0_n, iteration=iteration)\n",
    "print('After Bayesian optimisation, under alpha_opt =',alpha_opt,'the optimal k is:',k_opt,', with corresponding optimal RMSE_val_az:',rmse_opt)\n",
    "params = fit_nn(X=X_train, yy=y_train, alpha=alpha_opt, K=k_opt)\n",
    "rmse_test_az = rmse_compute_nn(X=X_test, yy=y_test, params=params)\n",
    "print('RMSE_test_az is:',rmse_test_az)\n",
    "#After Bayesian optimisation, the optimal alpha is: 2.9 , with corresponding optimal RMSE_val_a: 0.24249353747635613\n",
    "#RMSE_test_a is: 0.2640520595005275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75010700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_test_az is: 0.2412040833080041\n",
      "RMSE_test_az is: 0.261393623396327\n"
     ]
    }
   ],
   "source": [
    "params = fit_nn(X=X_train, yy=y_train, alpha=alpha_opt, K=19)\n",
    "rmse_val_az = rmse_compute_nn(X=X_val, yy=y_val, params=params)\n",
    "print('RMSE_test_az is:',rmse_val_az)\n",
    "rmse_test_az = rmse_compute_nn(X=X_test, yy=y_test, params=params)\n",
    "print('RMSE_test_az is:',rmse_test_az)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a1175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
